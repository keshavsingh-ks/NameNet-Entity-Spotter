{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUm8JqwW3lFk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    with open(file_path,'r') as file:\n",
        "        data = np.array([line.strip() for line in file.readlines()])\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "2vNWBeGv-gwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/ner_dataset.csv\", encoding=\"ISO-8859-1\")\n",
        "train_sents = load_data(\"/content/sentences.txt\")\n",
        "train_labels = load_data(\"/content/labels.txt\")"
      ],
      "metadata": {
        "id": "phVlGdz_34aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_sents = load_data(\"/content/val_sentences.txt\")\n",
        "val_label = load_data(\"/content/val_labels.txt\")\n",
        "print('SENTENCE:', val_sents)\n",
        "print('SENTENCE LABEL:', val_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV_k8I2g448z",
        "outputId": "fd512527-4aec-4d74-a342-9f86702c1a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SENTENCE: [\"Russia 's victory put the eight-time Olympic champions into the quarterfinals and also clinched a spot for Sweden .\"\n",
            " 'Slovakia advanced with a win over the United States ( 02-Jan ) on Saturday , leaving one remaining spot from Group-B .'\n",
            " 'China has announced its sixth human bird flu death .' ...\n",
            " 'Other sources of income are pearl farming and deep-sea commercial fishing .'\n",
            " 'The small manufacturing sector primarily processes agricultural products .'\n",
            " 'The territory benefits substantially from development agreements with France aimed principally at creating new businesses and strengthening social services .']\n",
            "SENTENCE LABEL: ['B-geo O O O O O O O O O O O O O O O O B-org O'\n",
            " 'B-geo O O O O O O B-geo I-geo O O O O B-tim O O O O O O B-art O'\n",
            " 'B-org O O O O O O O O O' ... 'O O O O O O O O O O O O'\n",
            " 'O O O O O O O O O' 'O O O O O O O O B-geo O O O O O O O O O O O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3RwMqQf2USj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sents = load_data(\"/content/test_sentences.txt\")\n",
        "test_label = load_data(\"/content/test_labels.txt\")\n",
        "print('SENTENCE:', test_sents)\n",
        "print('SENTENCE LABEL:', test_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4aB5jV75PTu",
        "outputId": "cb7b1a70-05dc-4b6f-85b6-0d4fb643e338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SENTENCE: ['Argentina benefits from rich natural resources , a highly literate population , an export-oriented agricultural sector , and a diversified industrial base .'\n",
            " \"Although one of the world 's wealthiest countries 100 years ago , Argentina suffered during most of the 20th century from recurring economic crises , persistent fiscal and current account deficits , high inflation , mounting external debt , and capital flight .\"\n",
            " \"A severe depression , growing public and external indebtedness , and a bank run culminated in 2001 in the most serious economic , social , and political crisis in the country 's turbulent history .\"\n",
            " ...\n",
            " \"Indian officials said no one was injured in Saturday 's incident but that two of the rockets landed near a border security outpost .\"\n",
            " 'Two more landed in fields belonging to a nearby village .'\n",
            " 'They say not all of the rockets exploded upon impact .']\n",
            "SENTENCE LABEL: ['B-geo O O O O O O O O O O O O O O O O O O O O O O'\n",
            " 'O O O O O O O O O O O O B-geo O O O O O B-tim O O O O O O O O O O O O O O O O O O O O O O O O'\n",
            " 'O O O O O O O O O O O O O O O O B-tim O O O O O O O O O O O O O O O O O O'\n",
            " ... 'B-gpe O O O O O O O B-tim O O O O O O O O O O O O O O O'\n",
            " 'O O O O O O O O O O O' 'O O O O O O O O O O O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(tf.keras.layers.TextVectorization)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5ydlubt55YMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_len = 0\n",
        "for sentence in open(\"/content/sentences.txt\", \"r\"):\n",
        "  sentence = sentence.strip()\n",
        "  words = sentence.split()\n",
        "  max_len = max(max_len, len(words))\n",
        "\n",
        "print(\"Maximum sentence length (in words):\", max_len)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsaUuI7B7CCc",
        "outputId": "4f711a2d-3d7e-4e38-daa4-8c235f5a4c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum sentence length (in words): 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: get_sentence_vectorizer\n",
        "def get_sentence_vectorizer(sentences):\n",
        "    tf.keras.utils.set_random_seed(33) ## Do not change this line.\n",
        "    ### START CODE HERE ###\n",
        "    # Define TextVectorization object with the appropriate standardize parameter\n",
        "    sentence_vectorizer = tf.keras.layers.TextVectorization(standardize=None, )\n",
        "    # Adapt the sentence vectorization object to the given sentences\n",
        "    sentence_vectorizer.adapt(sentences)\n",
        "    # Get the vocabulary\n",
        "    vocab = sentence_vectorizer.get_vocabulary()\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return sentence_vectorizer, vocab"
      ],
      "metadata": {
        "id": "RCZDIFdN6YK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_vectorizer, test_vocab = get_sentence_vectorizer(train_sents[:1000])\n",
        "print(f\"Test vocab size: {len(test_vocab)}\")\n",
        "\n",
        "sentence = \"I like learning new NLP models !\"\n",
        "sentence_vectorized = test_vectorizer(sentence)\n",
        "print(f\"Sentence: {sentence}\\nSentence vectorized: {sentence_vectorized}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNMlfHKS7xwQ",
        "outputId": "dbf462a1-3944-45c4-af1a-7a4564ed515f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test vocab size: 4650\n",
            "Sentence: I like learning new NLP models !\n",
            "Sentence vectorized: [ 296  314    1   59    1    1 4649]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_vectorizer, vocab = get_sentence_vectorizer(train_sents)\n",
        "print(f\"Vocabulary size: {len(vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bft5EYYt8JRQ",
        "outputId": "64074d54-8991-486c-8135-f4e65e6d14dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 29847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tags(labels):\n",
        "    tag_set = set() # Define an empty set\n",
        "    for el in labels:\n",
        "        for tag in el.split(\" \"):\n",
        "            tag_set.add(tag)\n",
        "    tag_list = list(tag_set)\n",
        "    tag_list.sort()\n",
        "    return tag_list"
      ],
      "metadata": {
        "id": "86Z6VGvd9QbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags = get_tags(train_labels)\n",
        "print(tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN91DCip99bC",
        "outputId": "682155ac-e4ea-45e6-efed-3bb45c740771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_tag_map(tags):\n",
        "    tag_map = {}\n",
        "    for idx, tag in enumerate(tags):\n",
        "        tag_map[tag] = idx\n",
        "    return tag_map"
      ],
      "metadata": {
        "id": "fbPk8O6I_J7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_map = make_tag_map(tags)\n",
        "print(tag_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_rMlSFD_Oob",
        "outputId": "16e5ee3e-7847-4cc9-a3c0-a3fca5933e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: label_vectorizer\n",
        "def label_vectorizer(labels, tag_map):\n",
        "    \"\"\"\n",
        "    Convert list of label strings to padded label IDs using a tag mapping.\n",
        "\n",
        "    Parameters:\n",
        "    labels (list of str): List of label strings.\n",
        "    tag_map (dict): Dictionary mapping tags to IDs.\n",
        "    Returns:\n",
        "    label_ids (numpy.ndarray): Padded array of label IDs.\n",
        "    \"\"\"\n",
        "    label_ids = [] # It can't be a numpy array yet, since each sentence has a different size\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Each element in labels is a string of tags so for each of them:\n",
        "    for element in labels:\n",
        "        # Split it into single tokens. You may use .split function for strings. Be aware to split it by a blank space!\n",
        "        tokens = element.split(\" \")\n",
        "\n",
        "        # Use the dictionaty tag_map passed as an argument to the label_vectorizer function\n",
        "        # to make the correspondence between tags and numbers.\n",
        "        element_ids = [tag_map[tag] for tag in tokens]\n",
        "\n",
        "        # Append the found ids to corresponding to the current element to label_ids list\n",
        "        label_ids.append(element_ids)\n",
        "\n",
        "    # Pad the elements\n",
        "    label_ids = tf.keras.utils.pad_sequences(label_ids, padding='post', value=-1)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return label_ids"
      ],
      "metadata": {
        "id": "e42FQwT0_TKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sentence: {train_sents[5]}\")\n",
        "print(f\"Labels: {train_labels[5]}\")\n",
        "print(f\"Vectorized labels: {label_vectorizer([train_labels[5]], tag_map)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pQSK7VCBq8v",
        "outputId": "11d69b7a-5ab0-4884-bd80-f8bf4d8f4045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: The party is divided over Britain 's participation in the Iraq conflict and the continued deployment of 8,500 British troops in that country .\n",
            "Labels: O O O O O B-gpe O O O O B-geo O O O O O O O B-gpe O O O O O\n",
            "Vectorized labels: [[16 16 16 16 16  3 16 16 16 16  2 16 16 16 16 16 16 16  3 16 16 16 16 16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset(sentences, labels, sentence_vectorizer, tag_map):\n",
        "    sentences_ids = sentence_vectorizer(sentences)\n",
        "    labels_ids = label_vectorizer(labels, tag_map = tag_map)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((sentences_ids, labels_ids))\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "htCGOMSLCMRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = generate_dataset(train_sents,train_labels, sentence_vectorizer, tag_map)\n",
        "val_dataset = generate_dataset(val_sents,val_label,  sentence_vectorizer, tag_map)\n",
        "test_dataset = generate_dataset(test_sents, test_label,  sentence_vectorizer, tag_map)"
      ],
      "metadata": {
        "id": "89wz5WvHCO2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring information about the training data\n",
        "print(f'The number of outputs is {len(tags)}')\n",
        "# The number of vocabulary tokens (including <PAD>)\n",
        "g_vocab_size = len(vocab)\n",
        "print(f\"Num of vocabulary words in the training set: {g_vocab_size}\")\n",
        "print('The training size is', len(train_dataset))\n",
        "print('The validation size is', len(val_dataset))\n",
        "print('An example of the first sentence is\\n\\t', next(iter(train_dataset))[0].numpy())\n",
        "print('An example of its corresponding label is\\n\\t', next(iter(train_dataset))[1].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsCPMwLOCaws",
        "outputId": "35fde61e-c0f9-41ed-935f-0d813799607a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of outputs is 17\n",
            "Num of vocabulary words in the training set: 29847\n",
            "The training size is 33570\n",
            "The validation size is 7194\n",
            "An example of the first sentence is\n",
            "\t [1046    6 1121   18 1832  232  543    7  528    2  158    5   60    9\n",
            "  648    2  922    6  192   87   22   16   54    3    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n",
            "An example of its corresponding label is\n",
            "\t [16 16 16 16 16 16  2 16 16 16 16 16  2 16 16 16 16 16  3 16 16 16 16 16\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def NER(len_tags, vocab_size, embedding_dim = 50):\n",
        "\n",
        "    model = tf.keras.Sequential(name='sequential')\n",
        "\n",
        "    # Add the tf.keras.layers.Embedding layer. Mask zeros to ignore padding in the sequences.\n",
        "    model.add(tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
        "                                        output_dim=embedding_dim,\n",
        "                                        mask_zero=True))  # Masking zero as padding\n",
        "\n",
        "    # Add the LSTM layer. Make sure it returns the full sequence (return_sequences=True).\n",
        "    model.add(tf.keras.layers.LSTM(units=embedding_dim, return_sequences=True))\n",
        "\n",
        "    # Add the final Dense layer with log softmax activation.\n",
        "    # len_tags is the number of NER tags (output classes)\n",
        "    model.add(tf.keras.layers.Dense(len_tags, activation=tf.nn.log_softmax))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OjUykvMtCtZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def masked_loss(y_true, y_pred):\n",
        "\n",
        "\n",
        "    y_true = tf.convert_to_tensor(y_true)\n",
        "    y_pred = tf.convert_to_tensor(y_pred)\n",
        "    # Calculate the loss for each item in the batch. Remember to pass the right arguments, as discussed above!\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, ignore_class=-1)\n",
        "    # Use the previous defined function to compute the loss\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return  loss"
      ],
      "metadata": {
        "id": "6HkWrWx8L5EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = [0,1,2,0]\n",
        "predicted_logits = [[-2.3,-0.51,-1.20] , [-1.61,-0.36,-2.30], [-2.30, -0.69,-0.92], [-0.92,-0.92,-1.61]]\n",
        "print(masked_loss(true_labels, predicted_logits))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuzgX48aMVZe",
        "outputId": "42d72a2e-6346-4a30-d02d-1a18f37d6180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1.1242604, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def masked_accuracy(y_true, y_pred):\n",
        "\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    # Create the mask, i.e., the values that will be ignored\n",
        "    mask = y_true != -1  # Mask where labels are valid (not -1)\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "    # Perform argmax to get the predicted values\n",
        "    y_pred_class = tf.argmax(y_pred, axis=-1)  # Get predicted class index\n",
        "    y_pred_class = tf.cast(y_pred_class, tf.float32)\n",
        "    # Compare the true values with the predicted ones\n",
        "    matches_true_pred  = tf.equal(x=y_true, y=y_pred_class)\n",
        "    matches_true_pred = tf.cast(matches_true_pred , tf.float32)\n",
        "    # Multiply the acc tensor with the masks\n",
        "    matches_true_pred *= mask\n",
        "    # Compute masked accuracy (quotient between the total matches and the total valid values, i.e., the amount of non-masked values)\n",
        "    # Cast tf.math.count_nonzero(mask) to tf.float32 to match the data type of tf.reduce_sum(matches_true_pred)\n",
        "    masked_acc = tf.reduce_sum(matches_true_pred) / tf.cast(tf.math.count_nonzero(mask), tf.float32)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return masked_acc"
      ],
      "metadata": {
        "id": "hxaUiAzvM0xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = [0,1,2,0]\n",
        "predicted_logits = [[0.1,0.6,0.3] , [0.2,0.7,0.1], [0.1, 0.5,0.4], [0.4,0.4,0.2]]\n",
        "print(masked_accuracy(true_labels, predicted_logits))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5IBI7XPNbgi",
        "outputId": "6af6ec22-d399-4efe-f6d6-04dfc9aa6042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.5, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NER(len(tag_map), len(vocab))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "662G8Z3FNbhp",
        "outputId": "962f2fe7-96cc-42b8-f249-4082bed65220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.expand_dims(np.array([545, 467, 896]), axis = 0) # Expanding dims is needed to pass it to the model,\n",
        "                                                        # since it expects batches and not single prediction arrays\n",
        "\n",
        "x_padded = tf.expand_dims(np.array([545, 467, 896, 0, 0, 0]), axis = 0)"
      ],
      "metadata": {
        "id": "L0xh4403RqaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ObQHTJiSf05",
        "outputId": "62b9f4ba-d5fb-4c10-b837-36a2e4562a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3), dtype=int64, numpy=array([[545, 467, 896]])>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_padded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKlXbMhwSgQt",
        "outputId": "9dbe7854-1288-4d35-9d23-b957215c4e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6), dtype=int64, numpy=array([[545, 467, 896,   0,   0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_x = model(x)\n",
        "pred_x_padded = model(x_padded)\n",
        "print(f'x shape: {pred_x.shape}\\nx_padded shape: {pred_x_padded.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7ZPNpHDShmU",
        "outputId": "20262e60-4251-4654-8f60-da5cd643ca61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape: (1, 3, 17)\n",
            "x_padded shape: (1, 6, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.allclose(pred_x, pred_x[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hlX1IFWS7JS",
        "outputId": "0faf17fe-a2ab-488b-d71a-d49e800c6aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = tf.expand_dims([16, 6, 12], axis = 0)\n",
        "y_true_padded = tf.expand_dims([16,6,12,-1,-1,-1], axis = 0) # Remember you mapped the padded values to -1 in the labels\n",
        "print(f\"masked_loss is the same: {np.allclose(masked_loss(y_true,pred_x), masked_loss(y_true_padded,pred_x_padded))}\")\n",
        "print(f\"masked_accuracy is the same: {np.allclose(masked_accuracy(y_true,pred_x), masked_accuracy(y_true_padded,pred_x_padded))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY8qVSs-S_sy",
        "outputId": "c3d9d17f-24a7-4c00-9b42-f8929d0e18e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "masked_loss is the same: True\n",
            "masked_accuracy is the same: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "              loss = masked_loss,\n",
        "               metrics = [masked_accuracy])"
      ],
      "metadata": {
        "id": "aDyvH4xqT27k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.set_random_seed(33)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "model.fit(train_dataset.batch(BATCH_SIZE),\n",
        "          validation_data = val_dataset.batch(BATCH_SIZE),\n",
        "          shuffle=True,\n",
        "          epochs = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj-S7vn-T-k0",
        "outputId": "88aab71c-768c-45a8-f230-d416d0c1f6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 124ms/step - loss: 0.4594 - masked_accuracy: 0.8952 - val_loss: 0.1393 - val_masked_accuracy: 0.9573\n",
            "Epoch 2/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 129ms/step - loss: 0.1299 - masked_accuracy: 0.9612 - val_loss: 0.1359 - val_masked_accuracy: 0.9584\n",
            "Epoch 3/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 126ms/step - loss: 0.1025 - masked_accuracy: 0.9679 - val_loss: 0.1387 - val_masked_accuracy: 0.9580\n",
            "Epoch 4/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 124ms/step - loss: 0.0886 - masked_accuracy: 0.9714 - val_loss: 0.1452 - val_masked_accuracy: 0.9575\n",
            "Epoch 5/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 121ms/step - loss: 0.0801 - masked_accuracy: 0.9736 - val_loss: 0.1536 - val_masked_accuracy: 0.9573\n",
            "Epoch 6/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 122ms/step - loss: 0.0735 - masked_accuracy: 0.9758 - val_loss: 0.1623 - val_masked_accuracy: 0.9562\n",
            "Epoch 7/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 123ms/step - loss: 0.0698 - masked_accuracy: 0.9769 - val_loss: 0.1716 - val_masked_accuracy: 0.9562\n",
            "Epoch 8/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 120ms/step - loss: 0.0672 - masked_accuracy: 0.9777 - val_loss: 0.1738 - val_masked_accuracy: 0.9553\n",
            "Epoch 9/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 124ms/step - loss: 0.0642 - masked_accuracy: 0.9787 - val_loss: 0.1829 - val_masked_accuracy: 0.9542\n",
            "Epoch 10/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 122ms/step - loss: 0.0594 - masked_accuracy: 0.9800 - val_loss: 0.1934 - val_masked_accuracy: 0.9531\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7effc3f9d600>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the sentences into ids\n",
        "test_sentences_id = sentence_vectorizer(test_sents)\n",
        "# Convert the labels into token ids\n",
        "test_labels_id = label_vectorizer(test_label,tag_map)\n",
        "# Rename to prettify next function call\n",
        "y_true = test_labels_id\n",
        "y_pred = model.predict(test_sentences_id)\n",
        "print(f\"The model's accuracy in test set is: {masked_accuracy(y_true,y_pred).numpy():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2rqdGLqUT48",
        "outputId": "11f6997d-5714-450a-be25-835d175df357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step\n",
            "The model's accuracy in test set is: 0.9530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: predict\n",
        "def predict(sentence, model, sentence_vectorizer, tag_map):\n",
        "\n",
        "    sentence_vectorized = sentence_vectorizer(sentence)\n",
        "    # Expand its dimension to make it appropriate to pass to the model\n",
        "    sentence_vectorized = tf.expand_dims(sentence_vectorized, axis = 0)\n",
        "    # Get the model output\n",
        "    output = model.predict(sentence_vectorized)\n",
        "    # Get the predicted labels for each token, using argmax function and specifying the correct axis to perform the argmax\n",
        "    outputs = np.argmax(output, axis = -1)\n",
        "    outputs = outputs[0]\n",
        "    # Get a list of all keys, remember that the tag_map was built in a way that each label id matches its index in a list\n",
        "    labels = list(tag_map.keys())\n",
        "    pred = []\n",
        "    # Iterating over every predicted token in outputs list\n",
        "    for tag_id in outputs:\n",
        "        # Append the corresponding label to the predictions list\n",
        "        pred.append(labels[tag_id])\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "toN0PQ4HUUZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Keshav Singh, A Artificial Inteligence enthusiast , said in an interview on Sunday morning that the model was working to prepare for the possibility of a second wave of optimisation, though he said it wouldn ’t necessarily come\"\n",
        "predictions = predict(sentence, model, sentence_vectorizer, tag_map)\n",
        "for x,y in zip(sentence.split(' '), predictions):\n",
        "    if y != 'O':\n",
        "        print(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfkaCU29WOYR",
        "outputId": "7241e1d2-8db5-4aac-c3b4-c598512c08d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
            "Singh, I-per\n",
            "A I-art\n",
            "Artificial B-tim\n",
            "Inteligence I-art\n",
            "enthusiast I-per\n",
            "Sunday B-tim\n",
            "morning I-tim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import io\n",
        "\n",
        "weights = model.layers[0].get_weights()[0]\n",
        "vocab = sentence_vectorizer.get_vocabulary()\n",
        "\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QRxBR9TdeMxa",
        "outputId": "37cdc149-e7e6-4470-8738-56d4cbb1fff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3cc6cdab-75d4-4f6f-9f6e-dd7fbc77fa6c\", \"vecs.tsv\", 16896838)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dcaaf1fd-f8c3-4346-890f-07831fd1ce95\", \"meta.tsv\", 255521)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}